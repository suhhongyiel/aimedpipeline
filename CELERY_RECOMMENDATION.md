# Celery 적용 검토 및 권장사항

## 현재 시스템 분석

### 현재 아키텍처
1. **직접 Docker 실행**: `subprocess.Popen`으로 Docker 컨테이너를 직접 실행
2. **Airflow 통합**: 선택적으로 Airflow DAG를 통해 실행 가능
3. **상태 추적**: PostgreSQL DB의 `MicaPipelineJob` 테이블로 상태 관리

### 현재 문제점
- FastAPI 엔드포인트가 동기적으로 Docker 실행을 기다림 (타임아웃 1시간)
- 여러 사용자가 동시에 요청하면 서버 부하 증가 가능
- 장기 실행 작업이 FastAPI 요청을 블로킹할 수 있음

## Celery 적용의 장단점

### 장점 ✅
1. **비동기 처리**: FastAPI가 즉시 응답하고 백그라운드에서 작업 실행
2. **작업 큐 관리**: Redis/RabbitMQ를 통한 작업 큐 관리
3. **확장성**: 여러 Worker로 작업 분산 가능
4. **재시도 및 에러 처리**: Celery의 내장 재시도 메커니즘 활용
5. **모니터링**: Flower를 통한 작업 모니터링

### 단점 ❌
1. **복잡도 증가**: Redis/RabbitMQ 브로커 추가 필요
2. **인프라 추가**: 브로커 서버 관리 필요
3. **현재 시스템과의 통합**: Airflow와의 중복 가능성

## 권장사항

### 옵션 1: Celery 적용 (권장하지 않음)
**이유:**
- 이미 Airflow가 작업 스케줄링 및 실행을 담당하고 있음
- Celery를 추가하면 두 개의 작업 큐 시스템이 공존하게 됨
- 복잡도만 증가하고 실질적 이점이 제한적

### 옵션 2: 현재 시스템 개선 (권장) ✅
**개선 방안:**

1. **FastAPI 비동기 처리 개선**
   - 현재 `subprocess.Popen`을 사용하여 백그라운드 실행 중
   - 이미 비동기적으로 동작하지만, 응답 개선 가능

2. **상태 폴링 최적화**
   - 클라이언트에서 주기적으로 상태 확인 (현재 구현됨)
   - WebSocket을 통한 실시간 업데이트 고려

3. **리소스 관리 개선**
   - 동시 실행 컨테이너 수 제한 (Docker Compose에서 설정 가능)
   - 작업 우선순위 큐 구현

4. **모니터링 강화**
   - 현재 DB 기반 상태 추적을 더욱 활용
   - 로그 집계 및 분석 도구 추가

### 옵션 3: Airflow만 사용 (장기적)
- 모든 작업을 Airflow로 통합
- FastAPI는 Airflow API 호출만 담당
- 더 일관된 워크플로우 관리

## 결론

**현재 시스템은 이미 잘 작동하고 있으며, Celery를 추가하는 것보다는:**

1. ✅ **현재 구현 개선**에 집중
   - 상태 업데이트 로직 개선 (완료)
   - 자동 새로고침 개선 (완료)
   - 사용자별 경로 분리 (완료)

2. ✅ **리소스 관리 강화**
   - 동시 실행 제한
   - 작업 큐 관리 (DB 기반)

3. ✅ **모니터링 개선**
   - 로그 집계
   - 성능 메트릭 수집

**Celery는 다음 경우에만 고려:**
- Airflow를 완전히 제거하고 싶을 때
- 더 세밀한 작업 제어가 필요할 때
- 분산 환경에서 여러 서버에 작업을 분산해야 할 때

## 현재 시스템으로 충분한 이유

1. ✅ Docker 컨테이너는 이미 백그라운드에서 실행됨
2. ✅ DB를 통한 상태 추적이 잘 작동함
3. ✅ Airflow가 이미 작업 스케줄링을 제공함
4. ✅ 사용자별 경로 분리로 격리가 가능함

**결론: Celery 적용은 현재 필요하지 않으며, 현재 시스템 개선에 집중하는 것이 더 효율적입니다.**

