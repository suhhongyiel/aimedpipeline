"""
íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í˜ì´ì§€ ëª¨ë“ˆ
"""
import streamlit as st
import time
import requests
from utils.common import show_progress_simulation
from utils.job_log_mock import get_mock_log

#####ì—¬ê¸° êµì²´í•¨ FASTAPI_SERVER_URL ë¶€ë¶„ êµì²´!!!!###########
# ë§¨ ìœ„ import ê·¼ì²˜ì— ì¶”ê°€
import os
import pandas as pd
from utils.styles import get_custom_css
from datetime import datetime


# FastAPI ì„œë²„ ì£¼ì†Œ (ë„ì»¤/ë¡œì»¬ ëª¨ë‘ ì§€ì›)
FASTAPI_SERVER_URL = os.getenv(
    "FASTAPI_SERVER_URL",
    st.secrets.get("api", {}).get("fastapi_base_url", "http://localhost:8000")
)
##############################################################
def _fmt_time_short(s: str, to_local: bool = True) -> str:
    """ISO ë¬¸ìì—´ â†’ HH:MM:SS (ë¡œì»¬ì‹œê°„)"""
    if not s:
        return ""
    try:
        dt = datetime.fromisoformat(str(s).replace("Z", "+00:00"))
        if to_local:
            dt = dt.astimezone()
        return dt.strftime("%H:%M:%S")          # ì›í•˜ë©´ "%m-%d %H:%M:%S"
    except Exception:
        # ì‹¤íŒ¨í•´ë„ ëŒ€ì¶© ì‹œ:ë¶„:ì´ˆë§Œ
        try:
            return str(s).split("T", 1)[1][:8]
        except Exception:
            return str(s)

def render():
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í˜ì´ì§€ ë Œë”ë§"""
    st.markdown(get_custom_css(), unsafe_allow_html=True)
    st.title("ğŸš€ Run Pipeline")
    st.markdown("---")
    
    # ì„ íƒëœ íŒŒì´í”„ë¼ì¸ì´ ìˆëŠ”ì§€ í™•ì¸
    if 'selected_pipeline' not in st.session_state or not st.session_state.selected_pipeline:
        st.warning("âš ï¸ Please select a pipeline first from the 'Select Pipeline' menu.")
        if st.button("ğŸ”§ Go to Select Pipeline"):
            st.session_state.selected_menu = 'Select Pipeline'
            st.rerun()
        return
    
    st.markdown(f"### Selected Pipeline: **{st.session_state.selected_pipeline}**")
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.markdown("#### ğŸ“ Data Upload")
    
    # íŒŒì´í”„ë¼ì¸ì— ë”°ë¼ ë‹¤ë¥¸ íŒŒì¼ íƒ€ì… í—ˆìš©
    pipeline_formats = {
        "MRI ë¶„ì„": ['dicom', 'nii', 'nrrd', 'gz']
    }
    
    allowed_types = pipeline_formats.get(st.session_state.selected_pipeline, ['jpg', 'png', 'csv'])
    # allowed_types = pipeline_formats.get(st.session_state.selected_pipeline, [])
    
    uploaded_files = st.file_uploader(
        f"Upload your {st.session_state.selected_pipeline} data files",
        type=allowed_types,
        accept_multiple_files=True,
        help=f"Supported formats: {', '.join(allowed_types)}"
    )
    
    if uploaded_files:
        st.success(f"âœ… {len(uploaded_files)} file(s) uploaded successfully!")
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
        with st.expander("ğŸ“‹ View uploaded files"):
            for i, file in enumerate(uploaded_files, 1):
                st.markdown(f"{i}. **{file.name}** ({file.size:,} bytes)")
    
    # íŒŒë¼ë¯¸í„° ì„¤ì • ì„¹ì…˜
    st.markdown("#### âš™ï¸ Pipeline Parameters")
    
    col1, col2 = st.columns(2)
    
    with col1:
        confidence_threshold = st.slider(
            "Confidence Threshold",
            min_value=0.0,
            max_value=1.0,
            value=0.8,
            step=0.05,
            help="Minimum confidence score for predictions"
        )
        
        batch_size = st.selectbox(
            "Batch Size",
            options=[1, 4, 8, 16, 32],
            index=2,
            help="Number of files to process simultaneously"
        )
    
    with col2:
        output_format = st.selectbox(
            "Output Format",
            options=['JSON', 'CSV', 'Excel'],
            index=0,
            help="Format for the analysis results"
        )
        
        enable_visualization = st.checkbox(
            "Enable Visualization", 
            value=True,
            help="Generate visual outputs and charts"
        )
    
    # ê³ ê¸‰ ì„¤ì •
    with st.expander("ğŸ”§ Advanced Settings"):
        col1, col2 = st.columns(2)
        
        with col1:
            preprocessing = st.checkbox("Apply Preprocessing", value=True)
            noise_reduction = st.checkbox("Noise Reduction", value=False)
        
        with col2:
            quality_check = st.checkbox("Quality Check", value=True)
            detailed_report = st.checkbox("Detailed Report", value=False)
    
    # ì‹¤í–‰ ë²„íŠ¼ ì„¹ì…˜
    st.markdown("---")
    st.markdown("#### ğŸ¯ Run Configuration Summary")
    
    # ì„¤ì • ìš”ì•½ í‘œì‹œ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
        **ğŸ“‹ Pipeline Settings:**
        - Pipeline: {st.session_state.selected_pipeline}
        - Files: {len(uploaded_files) if uploaded_files else 0}
        - Confidence: {confidence_threshold}
        - Batch Size: {batch_size}
        """)
    
    with col2:
        st.markdown(f"""
        **ğŸ›ï¸ Output Settings:**
        - Format: {output_format}
        - Visualization: {'Enabled' if enable_visualization else 'Disabled'}
        - Preprocessing: {'Enabled' if preprocessing else 'Disabled'}
        - Quality Check: {'Enabled' if quality_check else 'Disabled'}
        """)
    
    # ì‹¤í–‰ ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 1, 1])
    

    if st.button("ğŸš€ Run Pipeline", type="primary", use_container_width=True):
        if not uploaded_files:
            st.error("âŒ Please upload data files first!")
        else:

# ===========================================================================================================================
# ====================================================FastAPI============================================================

            # === ì‹¤í–‰ ë²„íŠ¼ ë‚´ë¶€ì˜ ì²˜ë¦¬ ë£¨í”„ ë¶€ë¶„ì„ ì´ ë¸”ë¡ìœ¼ë¡œ êµì²´ ===
            st.markdown("### ğŸ”„ Processing Status")
            progress_bar = st.progress(0, text="Initializing...")
            log_box = st.empty()
            table_box = st.empty()
            link_box = st.empty()

            try:
                log_box.info("â–¶ï¸ Sending job request to the server...")
                res = requests.post(f"{FASTAPI_SERVER_URL}/run-job", json={"job_type": st.session_state.selected_pipeline})
                res.raise_for_status()
                job_id = res.json()["job_id"]
                log_box.info(f"âœ… Job registered! (Job ID: {job_id})")
                progress_bar.progress(10, text="Job Queued...")

                while True:
                    res = requests.get(f"{FASTAPI_SERVER_URL}/job-status/{job_id}")
                    res.raise_for_status()
                    job_info = res.json()

                    status = (job_info.get("status") or "").upper()
                    progress = job_info.get("progress", 0)
                    tasks = job_info.get("tasks", [])

                    # í…Œì´ë¸” ë Œë”
                    if tasks:
                        df = pd.DataFrame(tasks)

                        # ë³´ê¸° ì¢‹ê²Œ ì •ë ¬
                        order = [
                            "1_bids_conversion", "2_proc_structural", "3_proc_surf",
                            "4_post_structural", "5_proc_func", "6_finalize_results"
                        ]
                        df["order"] = df["task_id"].apply(lambda x: order.index(x) if x in order else 999)
                        df = df.sort_values("order").drop(columns=["order"])

                        # â¬‡ï¸ ì‹œê°„ ì»¬ëŸ¼ ì§§ê²Œ ë³€í™˜ + try ìˆ«ìí™” + ì»¬ëŸ¼ëª… ê°„ë‹¨í™”
                        if "start_date" in df.columns:
                            df["start_date"] = df["start_date"].apply(_fmt_time_short)
                        if "end_date" in df.columns:
                            df["end_date"] = df["end_date"].apply(_fmt_time_short)
                        if "try_number" in df.columns:
                            df["try_number"] = df["try_number"].fillna(0).astype(int)

                        df = df.rename(columns={
                            "start_date": "start",
                            "end_date": "end",
                            "try_number": "try"
                        })

                        # ìƒíƒœ ì»¬ëŸ¬ë§
                        def _style(val):
                            v = (str(val) or "").lower()
                            if v == "success":
                                return 'background-color: #d4edda; color: #155724'
                            if v in ("running", "queued"):
                                return 'background-color: #fff3cd; color: #856404'
                            if v == "failed":
                                return 'background-color: #f8d7da; color: #721c24'
                            return ''

                        styled = df.style.applymap(_style, subset=["state"])
                        table_box.dataframe(styled, use_container_width=True, height=560)


                    link = job_info.get("airflow_ui")
                    if link:
                        link_box.markdown(f"ğŸ”— **Airflow Grid**: [{link}]({link})")

                    # Crash ê°ì§€ ë° ì‹¤íŒ¨í•œ task ë¶„ì„
                    failed_tasks = [t for t in tasks if (t.get("state") or "").lower() == "failed"]
                    
                    # ì§„í–‰ë°” ë° ìƒíƒœ í‘œì‹œ
                    if status in ("RUNNING","QUEUED"):
                        progress_bar.progress(min(max(progress, 15), 95), text="Processing...")
                        
                        # ì‹¤í–‰ ì¤‘ì—ë„ ì‹¤íŒ¨í•œ taskê°€ ìˆìœ¼ë©´ ê²½ê³ 
                        if failed_tasks:
                            log_box.warning(f"âš ï¸ {len(failed_tasks)} task(s) failed during execution")
                            
                    elif status == "SUCCESS":
                        progress_bar.progress(100, text="Completed!")
                        log_box.success("ğŸ‰ Job completed successfully!")
                        
                        # ì„±ê³µí–ˆì–´ë„ ì¬ì‹œë„ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸
                        retry_tasks = [t for t in tasks if t.get("try_number", 1) > 1]
                        if retry_tasks:
                            log_box.info(f"â„¹ï¸ {len(retry_tasks)} task(s) required retry")
                        break
                        
                    elif status == "FAILED":
                        progress_bar.progress(100, text="Failed!")
                        log_box.error(f"âŒ Job failed with {len(failed_tasks)} failed task(s)")
                        
                        # ì‹¤íŒ¨í•œ task ìƒì„¸ ì •ë³´ í‘œì‹œ
                        if failed_tasks:
                            with st.expander("ğŸ” Failed Tasks Details", expanded=True):
                                for task in failed_tasks:
                                    st.error(f"""
                                    **Task ID:** {task.get('task_id', 'Unknown')}
                                    - **State:** {task.get('state', 'Unknown')}
                                    - **Start:** {_fmt_time_short(task.get('start_date', ''))}
                                    - **End:** {_fmt_time_short(task.get('end_date', ''))}
                                    - **Tries:** {task.get('try_number', 0)}
                                    """)
                                
                                st.markdown("ğŸ’¡ **Troubleshooting Tips:**")
                                st.markdown("""
                                - Check Airflow logs for detailed error messages
                                - Verify input data format and completeness
                                - Check system resources (memory, disk space)
                                - Review task configuration and parameters
                                """)
                        
                        st.markdown(f"ğŸ”— [View detailed logs in Airflow]({link})")
                        break
                        
                    else:
                        progress_bar.progress(min(progress, 95), text=f"{status.title()}...")

                    time.sleep(2)

    # ===========================================================================================================================
    # ===========================================================================================================================

                # 3. ì‘ì—… ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ
                st.markdown("---")
                st.markdown("### ğŸ“Š Results Preview")
                
                # í˜„ì¬ëŠ” MRI ë¶„ì„ë§Œ ìˆìœ¼ë¯€ë¡œ, í•´ë‹¹ ê²°ê³¼ë§Œ í‘œì‹œ
                if st.session_state.selected_pipeline == "MRI ë¶„ì„":
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ë¶„ì„ëœ ìŠ¬ë¼ì´ìŠ¤", "128/150", "85.3%")
                    with col2:
                        st.metric("ì˜ì‹¬ ì˜ì—­", "3", "ë°œê²¬ë¨")
                
                # ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
                st.markdown("### ğŸ“¥ Download Results")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.download_button(
                        "ğŸ“„ Download Report",
                        data=f"Analysis report for {st.session_state.selected_pipeline}",
                        file_name="analysis_report.pdf",
                        mime="application/pdf"
                    )
                
                with col2:
                    if st.button("ğŸ“Š View Full Results"):
                        st.session_state.selected_menu = 'Download Results'
                        st.rerun()
                
                with col3:
                    st.download_button(
                        "ğŸ’¾ Save Configuration",
                        data=f"Pipeline config: {st.session_state.selected_pipeline}",
                        file_name="config.json",
                        mime="application/json"
                    )

        # ===========================================================================================================================
        # ====================================================FastAPI==============================================================
                
            except requests.exceptions.ConnectionError:
                st.error("âŒ Connection Error: Could not connect to the FastAPI server. Is it running?")
            except requests.exceptions.HTTPError as e:
                st.error(f"âŒ HTTP Error: {e.response.status_code} - {e.response.text}")

        # ===========================================================================================================================
        # ===========================================================================================================================